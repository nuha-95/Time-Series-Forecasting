{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2981cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 0.00019191030193900816\n",
      "Mean Squared Error: 0.00\n",
      "Root Mean Squared Error: 0.01\n",
      "Mean Absolute Error: 0.01\n",
      "R² Score: 1.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25324\\3888213936.py:25: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df['Monthly Return'] = df['Close'].resample('M').ffill().pct_change()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25324\\3888213936.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Monthly Return'].fillna(method='bfill', inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25324\\3888213936.py:26: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Monthly Return'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./Tasla_Stock_Updated_V2.csv')  # Update filename accordingly\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Handle missing values\n",
    "df = df.dropna()\n",
    "\n",
    "# Feature Engineering\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "df['Volatility'] = df['Close'].rolling(window=10).std()\n",
    "df['target']=df['Close'].shift(-1)\n",
    "\n",
    "# Monthly Returns (Resample to monthly and calculate returns)\n",
    "df['Monthly Return'] = df['Close'].resample('M').ffill().pct_change()\n",
    "df['Monthly Return'].fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Drop NaNs after feature creation\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Select features and target\n",
    "features = [\n",
    "    # 'MA5', 'MA10', 'Monthly Return',\n",
    "            'Open', 'High', 'Low', 'Close', 'target']\n",
    "target = 'target'\n",
    "\n",
    "# Standardize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n",
    "# y = df[target].values\n",
    "y_scaled=X_scaled[:,-1]\n",
    "X_scaled=X_scaled[:,0:-1]\n",
    "\n",
    "# scaler_y=MinMaxScaler()\n",
    "\n",
    "# y_scaled=scaler.fit_transform(df[target])\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train Linear Regression Model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Test MSE: {mse}\")\n",
    "\n",
    "# Optional: Plot\n",
    "\n",
    "\n",
    "# Calculate MSE\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
    "print(f\"R² Score: {r2:.2f}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98ef1417",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5cdd2ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('./Tasla_Stock_Updated_V2.csv')  \n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e53bc1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "379629df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d1b01cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "df['Volatility'] = df['Close'].rolling(window=10).std()\n",
    "df['target']=df['Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bbb051fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25324\\2697594030.py:2: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df['Monthly Return'] = df['Close'].resample('M').ffill().pct_change()\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25324\\2697594030.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Monthly Return'].fillna(method='bfill', inplace=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_25324\\2697594030.py:3: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['Monthly Return'].fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Monthly Returns (Resample to monthly and calculate returns)\n",
    "df['Monthly Return'] = df['Close'].resample('M').ffill().pct_change()\n",
    "df['Monthly Return'].fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11be484",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e350a959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01022268, 0.00865982, 0.01042236, 0.00997855],\n",
       "       [0.01022434, 0.00939879, 0.01047284, 0.01120069],\n",
       "       [0.01175841, 0.01078766, 0.0118137 , 0.01243614],\n",
       "       ...,\n",
       "       [0.56517952, 0.58557388, 0.56681163, 0.59227457],\n",
       "       [0.5963501 , 0.59980073, 0.58889291, 0.58583088],\n",
       "       [0.58622525, 0.58116975, 0.57413002, 0.57569083]], shape=(2225, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e068e54b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.55400205 0.59841537 0.32245768 0.54114862 0.53963559 0.53763072\n",
      " 0.53464771]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aae58bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARIMA RMSE: 114.61\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n",
      "  return get_prediction_index(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./Tasla_Stock_Updated_V2.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Use the 'Close' price\n",
    "ts = df['Close'].dropna()\n",
    "\n",
    "# Train-test split\n",
    "train_size = int(len(ts) * 0.8)\n",
    "train, test = ts[:train_size], ts[train_size:]\n",
    "\n",
    "# Fit ARIMA model\n",
    "model = ARIMA(train, order=(5, 1, 0))  # (p, d, q)\n",
    "model_fit = model.fit()\n",
    "\n",
    "# Forecast\n",
    "forecast = model_fit.forecast(steps=len(test))\n",
    "\n",
    "# Evaluate model\n",
    "rmse = sqrt(mean_squared_error(test, forecast))\n",
    "print(f'ARIMA RMSE: {rmse:.2f}')\n",
    "\n",
    "# Plot actual vs predicted\n",
    "# plt.figure(figsize=(10, 5))\n",
    "# plt.plot(test.index, test, label='Actual')\n",
    "# plt.plot(test.index, forecast, label='Forecast', linestyle='--')\n",
    "# plt.title('ARIMA Forecast vs Actual - Tesla Stock')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Price')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52aca8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 11.73\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Tasla_Stock_Updated_V2.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Calculate moving averages\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Shift Close price to create prediction target (next day)\n",
    "df['Target'] = df['Close'].shift(-1)\n",
    "\n",
    "# Drop rows with NaN values due to rolling or shift\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Features and target\n",
    "features = df[['MA5', 'MA10', 'MA20']]\n",
    "target = df['Target']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "\n",
    "# Plot\n",
    "# plt.figure(figsize=(12, 6))\n",
    "# plt.plot(y_test.index, y_test, label='Actual')\n",
    "# plt.plot(y_test.index, y_pred, label='Predicted', linestyle='--')\n",
    "# plt.title('Linear Regression: Predicting Next Day Close using MAs')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Stock Price')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "655bca96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.49\n",
      "[[ 80 141]\n",
      " [ 88 142]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.36      0.41       221\n",
      "           1       0.50      0.62      0.55       230\n",
      "\n",
      "    accuracy                           0.49       451\n",
      "   macro avg       0.49      0.49      0.48       451\n",
      "weighted avg       0.49      0.49      0.48       451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('Tasla_Stock_Updated_V2.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['Return'] = df['Close'].pct_change()\n",
    "df['Volatility'] = df['Return'].rolling(window=5).std()\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "\n",
    "# Create target: 1 if next day return > 0, else 0\n",
    "df['Target'] = (df['Return'].shift(-1) > 0).astype(int)\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Features and target\n",
    "features = df[['MA5', 'MA10', 'MA20', 'Volatility', 'Return']]\n",
    "target = df['Target']\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Model training\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {acc:.2f}\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae8602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import GRU, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Tesla_Stock.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "# Feature engineering\n",
    "df['Return'] = df['Close'].pct_change()\n",
    "df['Volatility'] = df['Return'].rolling(window=5).std()\n",
    "df['MA5'] = df['Close'].rolling(window=5).mean()\n",
    "df['MA10'] = df['Close'].rolling(window=10).mean()\n",
    "df['MA20'] = df['Close'].rolling(window=20).mean()\n",
    "df['Target'] = (df['Return'].shift(-1) > 0).astype(int)\n",
    "\n",
    "# Drop NaNs\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Features and target\n",
    "features = df[['MA5', 'MA10', 'MA20', 'Volatility', 'Return']]\n",
    "target = df['Target']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Create sequences for GRU\n",
    "X, y = [], []\n",
    "sequence_length = 10  # use past 10 days to predict\n",
    "\n",
    "for i in range(len(features_scaled) - sequence_length):\n",
    "    X.append(features_scaled[i:i + sequence_length])\n",
    "    y.append(target.iloc[i + sequence_length])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "# Train-test split\n",
    "split = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split], X[split:]\n",
    "y_train, y_test = y[:split], y[split:]\n",
    "\n",
    "# Build GRU model\n",
    "model = Sequential()\n",
    "model.add(GRU(64, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=16, validation_data=(X_test, y_test), verbose=1)\n",
    "\n",
    "# Predict\n",
    "y_pred_prob = model.predict(X_test)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f'GRU Accuracy: {acc:.2f}')\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ee6ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# import xgboost as xgb\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "# from tensorflow.keras.callbacks import EarlyStopping\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "# # Data loading and preparation functions\n",
    "# def dataloader():\n",
    "#     df = pd.read_csv('./Tasla_Stock_Updated_V2.csv')  \n",
    "#     df['Date'] = pd.to_datetime(df['Date'])\n",
    "#     df.set_index('Date', inplace=True)\n",
    "#     df = df.dropna()\n",
    "#     return df\n",
    "\n",
    "# def add_features(df):\n",
    "#     df = df.copy()\n",
    "#     # Technical indicators\n",
    "#     df['MA5'] = df['Close'].rolling(window=5).mean().shift(1)\n",
    "#     df['MA10'] = df['Close'].rolling(window=10).mean().shift(1)\n",
    "#     df['MA20'] = df['Close'].rolling(window=20).mean().shift(1)\n",
    "#     df['MA50'] = df['Close'].rolling(window=50).mean().shift(1)\n",
    "    \n",
    "#     # Volatility features\n",
    "#     df['Volatility_10d'] = df['Close'].rolling(window=10).std().shift(1)\n",
    "#     df['Volatility_20d'] = df['Close'].rolling(window=20).std().shift(1)\n",
    "    \n",
    "#     # Price momentum features\n",
    "#     df['Momentum_1d'] = df['Close'].pct_change(periods=1).shift(1)\n",
    "#     df['Momentum_5d'] = df['Close'].pct_change(periods=5).shift(1)\n",
    "#     df['Momentum_10d'] = df['Close'].pct_change(periods=10).shift(1)\n",
    "    \n",
    "#     # Trading volume features\n",
    "#     if 'Volume' in df.columns:\n",
    "#         df['Volume_Change'] = df['Volume'].pct_change().shift(1)\n",
    "#         df['Volume_MA5'] = df['Volume'].rolling(window=5).mean().shift(1)\n",
    "#         df['Volume_MA10'] = df['Volume'].rolling(window=10).mean().shift(1)\n",
    "    \n",
    "#     # Price relative to moving averages\n",
    "#     df['Price_to_MA5'] = df['Close'].shift(1) / df['MA5'] - 1\n",
    "#     df['Price_to_MA10'] = df['Close'].shift(1) / df['MA10'] - 1\n",
    "#     df['Price_to_MA20'] = df['Close'].shift(1) / df['MA20'] - 1\n",
    "    \n",
    "#     # Monthly Return\n",
    "#     monthly_return = df['Close'].resample('M').ffill().pct_change().shift(1)\n",
    "#     monthly_return = monthly_return.fillna(method='bfill')\n",
    "#     df['Monthly_Return'] = monthly_return.resample('D').ffill().reindex(df.index, method='ffill')\n",
    "    \n",
    "#     # Target: next day's closing price\n",
    "#     df['target'] = df['Close'].shift(-1)\n",
    "    \n",
    "#     # Remove rows with missing values\n",
    "#     df.dropna(inplace=True)\n",
    "#     return df\n",
    "\n",
    "# # Load and prepare data\n",
    "# df = dataloader()\n",
    "# df = add_features(df)\n",
    "\n",
    "# # Define features that don't include the current price (no data leakage)\n",
    "# features = [\n",
    "#     'MA5', 'MA10', 'MA20', 'MA50', \n",
    "#     'Volatility_10d', 'Volatility_20d',\n",
    "#     'Momentum_1d', 'Momentum_5d', 'Momentum_10d',\n",
    "#     'Price_to_MA5', 'Price_to_MA10', 'Price_to_MA20',\n",
    "#     'Monthly_Return'\n",
    "# ]\n",
    "\n",
    "# # Add Volume features if available\n",
    "# if 'Volume' in df.columns:\n",
    "#     features.extend(['Volume_Change', 'Volume_MA5', 'Volume_MA10'])\n",
    "\n",
    "# # Remove any features that might not be available due to data structure\n",
    "# features = [f for f in features if f in df.columns]\n",
    "\n",
    "# # Prepare data\n",
    "# X = df[features]\n",
    "# y = df['target']\n",
    "\n",
    "# # Train-test split (no shuffling for time series)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=0.2, random_state=42, shuffle=False\n",
    "# )\n",
    "\n",
    "# # Scale features\n",
    "# scaler_X = MinMaxScaler()\n",
    "# X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "# X_test_scaled = scaler_X.transform(X_test)\n",
    "\n",
    "# # Create a price scaler for LSTM (to inverse transform predictions later)\n",
    "# scaler_y = MinMaxScaler()\n",
    "# y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "# y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1))\n",
    "\n",
    "# # Function to evaluate and display model results\n",
    "# def evaluate_model(model_name, y_true, y_pred):\n",
    "#     mse = mean_squared_error(y_true, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     mae = mean_absolute_error(y_true, y_pred)\n",
    "#     r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "#     print(f\"\\n{model_name} Performance:\")\n",
    "#     print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "#     print(f\"Root Mean Squared Error: {rmse:.4f}\")\n",
    "#     print(f\"Mean Absolute Error: {mae:.4f}\")\n",
    "#     print(f\"R² Score: {r2:.4f}\")\n",
    "    \n",
    "#     # Plot predictions vs actual\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "#     plt.plot(y_test.index, y_true, label='Actual')\n",
    "#     plt.plot(y_test.index, y_pred, label=f'{model_name} Prediction', linestyle='--')\n",
    "#     plt.title(f'Tesla Stock Price Prediction with {model_name}')\n",
    "#     plt.xlabel('Date')\n",
    "#     plt.ylabel('Price')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "#     return {'mse': mse, 'rmse': rmse, 'mae': mae, 'r2': r2}\n",
    "\n",
    "# # ==============================\n",
    "# # 1. Random Forest Model\n",
    "# # ==============================\n",
    "# def train_random_forest():\n",
    "#     print(\"\\n=== Training Random Forest Model ===\")\n",
    "    \n",
    "#     # Parameter tuning can be done with GridSearchCV\n",
    "#     rf_model = RandomForestRegressor(\n",
    "#         n_estimators=100,\n",
    "#         max_depth=15,\n",
    "#         min_samples_split=5,\n",
    "#         min_samples_leaf=2,\n",
    "#         random_state=42,\n",
    "#         n_jobs=-1\n",
    "#     )\n",
    "    \n",
    "#     # Train the model\n",
    "#     rf_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "#     # Make predictions\n",
    "#     y_pred_rf = rf_model.predict(X_test_scaled)\n",
    "    \n",
    "#     # Evaluate\n",
    "#     results = evaluate_model(\"Random Forest\", y_test.values, y_pred_rf)\n",
    "    \n",
    "#     # Feature importance\n",
    "#     feature_importance = pd.DataFrame({\n",
    "#         'Feature': features,\n",
    "#         'Importance': rf_model.feature_importances_\n",
    "#     }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "#     print(\"\\nRandom Forest Feature Importance:\")\n",
    "#     print(feature_importance.head(10))\n",
    "    \n",
    "#     return rf_model, results\n",
    "\n",
    "# # ==============================\n",
    "# # 2. XGBoost Model\n",
    "# # ==============================\n",
    "# def train_xgboost():\n",
    "#     print(\"\\n=== Training XGBoost Model ===\")\n",
    "    \n",
    "#     # Parameter tuning can be done with GridSearchCV\n",
    "#     xgb_model = xgb.XGBRegressor(\n",
    "#         n_estimators=100,\n",
    "#         learning_rate=0.1,\n",
    "#         max_depth=5,\n",
    "#         subsample=0.8,\n",
    "#         colsample_bytree=0.8,\n",
    "#         random_state=42\n",
    "#     )\n",
    "    \n",
    "#     # Train the model\n",
    "#     xgb_model.fit(\n",
    "#         X_train_scaled, y_train,\n",
    "#         eval_set=[(X_test_scaled, y_test)],\n",
    "#         eval_metric='rmse',\n",
    "#         early_stopping_rounds=20,\n",
    "#         verbose=False\n",
    "#     )\n",
    "    \n",
    "#     # Make predictions\n",
    "#     y_pred_xgb = xgb_model.predict(X_test_scaled)\n",
    "    \n",
    "#     # Evaluate\n",
    "#     results = evaluate_model(\"XGBoost\", y_test.values, y_pred_xgb)\n",
    "    \n",
    "#     # Feature importance\n",
    "#     feature_importance = pd.DataFrame({\n",
    "#         'Feature': features,\n",
    "#         'Importance': xgb_model.feature_importances_\n",
    "#     }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "#     print(\"\\nXGBoost Feature Importance:\")\n",
    "#     print(feature_importance.head(10))\n",
    "    \n",
    "#     return xgb_model, results\n",
    "\n",
    "# # ==============================\n",
    "# # 3. LSTM Model\n",
    "# # ==============================\n",
    "# def create_sequences(X, y, time_steps=10):\n",
    "#     X_seq, y_seq = [], []\n",
    "#     for i in range(len(X) - time_steps):\n",
    "#         X_seq.append(X[i:i + time_steps])\n",
    "#         y_seq.append(y[i + time_steps])\n",
    "#     return np.array(X_seq), np.array(y_seq)\n",
    "\n",
    "# def train_lstm():\n",
    "#     print(\"\\n=== Training LSTM Model ===\")\n",
    "    \n",
    "#     # Parameter for sequence creation\n",
    "#     time_steps = 10\n",
    "    \n",
    "#     # Create sequences for LSTM\n",
    "#     X_train_seq, y_train_seq = create_sequences(X_train_scaled, y_train_scaled, time_steps)\n",
    "#     X_test_seq, y_test_seq = create_sequences(X_test_scaled, y_test_scaled, time_steps)\n",
    "    \n",
    "#     # Build LSTM model\n",
    "#     lstm_model = Sequential([\n",
    "#         LSTM(50, return_sequences=True, input_shape=(time_steps, X_train_scaled.shape[1])),\n",
    "#         Dropout(0.2),\n",
    "#         LSTM(50),\n",
    "#         Dropout(0.2),\n",
    "#         Dense(1)\n",
    "#     ])\n",
    "    \n",
    "#     # Compile model\n",
    "#     lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    \n",
    "#     # Early stopping to prevent overfitting\n",
    "#     early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    \n",
    "#     # Train model\n",
    "#     history = lstm_model.fit(\n",
    "#         X_train_seq, y_train_seq,\n",
    "#         epochs=50,\n",
    "#         batch_size=32,\n",
    "#         validation_split=0.2,\n",
    "#         callbacks=[early_stop],\n",
    "#         verbose=1\n",
    "#     )\n",
    "    \n",
    "#     # Plot training history\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(history.history['loss'], label='Training Loss')\n",
    "#     plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "#     plt.title('LSTM Model Loss')\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss (MSE)')\n",
    "#     plt.legend()\n",
    "#     plt.grid(True)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Make predictions\n",
    "#     y_pred_lstm_scaled = lstm_model.predict(X_test_seq)\n",
    "    \n",
    "#     # Inverse transform to get actual prices\n",
    "#     y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled)\n",
    "    \n",
    "#     # Note: for proper comparison, we need to align the test set\n",
    "#     y_test_aligned = y_test.iloc[time_steps:].values\n",
    "    \n",
    "#     # Evaluate\n",
    "#     results = evaluate_model(\"LSTM\", y_test_aligned, y_pred_lstm)\n",
    "    \n",
    "#     return lstm_model, results\n",
    "\n",
    "# # Run all models and compare\n",
    "# rf_model, rf_results = train_random_forest()\n",
    "# xgb_model, xgb_results = train_xgboost()\n",
    "# lstm_model, lstm_results = train_lstm()\n",
    "\n",
    "# # Compare models\n",
    "# models = ['Linear Regression', 'Random Forest', 'XGBoost', 'LSTM']\n",
    "# metrics = ['mse', 'rmse', 'mae', 'r2']\n",
    "\n",
    "# # Assuming linear regression results from previous run\n",
    "# lr_results = {\n",
    "#     'mse': 182.0110,\n",
    "#     'rmse': 13.4911,\n",
    "#     'mae': 10.5450,\n",
    "#     'r2': 0.9279\n",
    "# }\n",
    "\n",
    "# # Create comparison table\n",
    "# results_df = pd.DataFrame([\n",
    "#     lr_results,\n",
    "#     rf_results,\n",
    "#     xgb_results,\n",
    "#     lstm_results\n",
    "# ], index=models)\n",
    "\n",
    "# print(\"\\n=== Model Comparison ===\")\n",
    "# print(results_df)\n",
    "\n",
    "# # Plot comparison\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# plt.subplot(2, 2, 1)\n",
    "# plt.bar(models, results_df['mse'])\n",
    "# plt.title('MSE Comparison')\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.subplot(2, 2, 2)\n",
    "# plt.bar(models, results_df['rmse'])\n",
    "# plt.title('RMSE Comparison')\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.subplot(2, 2, 3)\n",
    "# plt.bar(models, results_df['mae'])\n",
    "# plt.title('MAE Comparison')\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.subplot(2, 2, 4)\n",
    "# plt.bar(models, results_df['r2'])\n",
    "# plt.title('R² Score Comparison')\n",
    "# plt.xticks(rotation=45)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
